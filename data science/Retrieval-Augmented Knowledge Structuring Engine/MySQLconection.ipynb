{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d33824",
   "metadata": {},
   "source": [
    "#### Desnormalizando datos de nuestra base de datos SQL del delivery para juntar informaci√≥n relevante en un solo objeto JSON/TEXTO Optimizado para: B√∫squeda sem√°ntica, contexto completo, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ec64c05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conexi√≥n exitosa a MySQL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>horario_apertura</th>\n",
       "      <th>horario_cierre</th>\n",
       "      <th>diasOperacion</th>\n",
       "      <th>direccion</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>descripcion_detallada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>TACOS LOS LICENCIADOS</td>\n",
       "      <td>Tacos de carne asada</td>\n",
       "      <td>0 days 12:02:14</td>\n",
       "      <td>0 days 16:24:56</td>\n",
       "      <td>S√°bado a Domingo</td>\n",
       "      <td>Calle 66, Ciudad 16</td>\n",
       "      <td>2025-12-23 23:13:39</td>\n",
       "      <td>2025-09-23 21:54:51</td>\n",
       "      <td>Negocio de comida que ofrece tacos de asada en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>02-PIZZA CENTRAL</td>\n",
       "      <td>Pizzas, papas y hamburguesas</td>\n",
       "      <td>0 days 13:21:26</td>\n",
       "      <td>0 days 19:43:15</td>\n",
       "      <td>Lunes a Viernes</td>\n",
       "      <td>Calle 96, Ciudad 50</td>\n",
       "      <td>2025-12-26 12:52:28</td>\n",
       "      <td>2025-09-23 21:57:17</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>DESAYUNOS GAHORY</td>\n",
       "      <td>Desayunos en general</td>\n",
       "      <td>0 days 09:03:39</td>\n",
       "      <td>0 days 17:33:48</td>\n",
       "      <td>Mi√©rcoles a Domingo</td>\n",
       "      <td>Calle 65, Ciudad 43</td>\n",
       "      <td>2025-12-24 11:32:03</td>\n",
       "      <td>2025-09-23 21:58:13</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>02-EXPRESSO CENTRAL</td>\n",
       "      <td>Cafeter√≠a, crepas y m√°s</td>\n",
       "      <td>0 days 11:04:55</td>\n",
       "      <td>0 days 21:53:39</td>\n",
       "      <td>Lunes a Domingo</td>\n",
       "      <td>Calle 15, Ciudad 33</td>\n",
       "      <td>2025-12-26 12:52:34</td>\n",
       "      <td>2025-09-23 21:59:43</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>HAMBURGUESAS \"EL G√úERO\"</td>\n",
       "      <td>Hamburguesas, papas, hot-dogs</td>\n",
       "      <td>0 days 16:24:01</td>\n",
       "      <td>0 days 14:21:40</td>\n",
       "      <td>Jueves a Domingo</td>\n",
       "      <td>Calle 60, Ciudad 50</td>\n",
       "      <td>2025-12-23 23:13:58</td>\n",
       "      <td>2025-09-23 22:00:19</td>\n",
       "      <td>Negocio de comida r√°pida que ofrece hamburgues...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                     name                    description  \\\n",
       "0  31    TACOS LOS LICENCIADOS           Tacos de carne asada   \n",
       "1  33         02-PIZZA CENTRAL   Pizzas, papas y hamburguesas   \n",
       "2  34         DESAYUNOS GAHORY           Desayunos en general   \n",
       "3  35      02-EXPRESSO CENTRAL        Cafeter√≠a, crepas y m√°s   \n",
       "4  36  HAMBURGUESAS \"EL G√úERO\"  Hamburguesas, papas, hot-dogs   \n",
       "\n",
       "  horario_apertura  horario_cierre        diasOperacion            direccion  \\\n",
       "0  0 days 12:02:14 0 days 16:24:56     S√°bado a Domingo  Calle 66, Ciudad 16   \n",
       "1  0 days 13:21:26 0 days 19:43:15      Lunes a Viernes  Calle 96, Ciudad 50   \n",
       "2  0 days 09:03:39 0 days 17:33:48  Mi√©rcoles a Domingo  Calle 65, Ciudad 43   \n",
       "3  0 days 11:04:55 0 days 21:53:39      Lunes a Domingo  Calle 15, Ciudad 33   \n",
       "4  0 days 16:24:01 0 days 14:21:40     Jueves a Domingo  Calle 60, Ciudad 50   \n",
       "\n",
       "           created_at           updated_at  \\\n",
       "0 2025-12-23 23:13:39  2025-09-23 21:54:51   \n",
       "1 2025-12-26 12:52:28  2025-09-23 21:57:17   \n",
       "2 2025-12-24 11:32:03  2025-09-23 21:58:13   \n",
       "3 2025-12-26 12:52:34  2025-09-23 21:59:43   \n",
       "4 2025-12-23 23:13:58  2025-09-23 22:00:19   \n",
       "\n",
       "                               descripcion_detallada  \n",
       "0  Negocio de comida que ofrece tacos de asada en...  \n",
       "1                                               None  \n",
       "2                                               None  \n",
       "3                                               None  \n",
       "4  Negocio de comida r√°pida que ofrece hamburgues...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "# === DATOS DE CONEXI√ìN ===\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = quote_plus(os.getenv(\"DB_PASS\", \"\")) # se codifica aqu√≠\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "# === ENGINE ===\n",
    "engine = create_engine(\n",
    "    f\"mysql+pymysql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\",\n",
    "    pool_pre_ping=True\n",
    ")\n",
    "\n",
    "# === PRUEBA DE CONEXI√ìN ===\n",
    "with engine.connect() as conn:\n",
    "    print(\"‚úÖ Conexi√≥n exitosa a MySQL\")\n",
    "\n",
    "# === CARGAR TABLA ===\n",
    "negocios = pd.read_sql(\"\"\"\n",
    "SELECT\n",
    "  id,\n",
    "  name,\n",
    "  description,\n",
    "  horario_apertura,\n",
    "  horario_cierre,\n",
    "  diasOperacion,\n",
    "  direccion,\n",
    "  created_at,\n",
    "  updated_at,\n",
    "  descripcion_detallada\n",
    "FROM categories\n",
    "\"\"\", engine)\n",
    "\n",
    "negocios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86eaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6400e3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>image1</th>\n",
       "      <th>image2</th>\n",
       "      <th>image3</th>\n",
       "      <th>id_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>ENCHILADAS(DESAYUNOS GAHORY)</td>\n",
       "      <td>CAMPIRANO:VERDES:POLLO / HUEVO</td>\n",
       "      <td>70.0</td>\n",
       "      <td>https://firebasestorage.googleapis.com/v0/b/te...</td>\n",
       "      <td>https://firebasestorage.googleapis.com/v0/b/te...</td>\n",
       "      <td>https://firebasestorage.googleapis.com/v0/b/te...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>ENCHILADAS NORTE√ëA(DESAYUNOS GAHORY)</td>\n",
       "      <td>ROJAS C/PECHUGA ASADA ENCEBOLLADA</td>\n",
       "      <td>85.0</td>\n",
       "      <td>https://firebasestorage.googleapis.com/v0/b/te...</td>\n",
       "      <td>https://firebasestorage.googleapis.com/v0/b/te...</td>\n",
       "      <td>https://firebasestorage.googleapis.com/v0/b/te...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>ENCHILADAS SUIZO(DESAYUNOS GAHORY)</td>\n",
       "      <td>EN SALSA CREMOSITA GRATINADAS EN QUESO MANCHEGO</td>\n",
       "      <td>95.0</td>\n",
       "      <td>https://firebasestorage.googleapis.com/v0/b/te...</td>\n",
       "      <td>https://firebasestorage.googleapis.com/v0/b/te...</td>\n",
       "      <td>https://firebasestorage.googleapis.com/v0/b/te...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>ENCHILADAS DELICIA(DESAYUNOS GAHORY)</td>\n",
       "      <td>DIVORCIADAS</td>\n",
       "      <td>85.0</td>\n",
       "      <td>https://firebasestorage.googleapis.com/v0/b/te...</td>\n",
       "      <td>https://firebasestorage.googleapis.com/v0/b/te...</td>\n",
       "      <td>https://firebasestorage.googleapis.com/v0/b/te...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>ENCHILADAS PAISA(DESAYUNOS GAHORY)</td>\n",
       "      <td>ENCHILADAS EN SALSA DE FRIJOL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>https://firebasestorage.googleapis.com/v0/b/te...</td>\n",
       "      <td>https://firebasestorage.googleapis.com/v0/b/te...</td>\n",
       "      <td>https://firebasestorage.googleapis.com/v0/b/te...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                  name  \\\n",
       "0  38          ENCHILADAS(DESAYUNOS GAHORY)   \n",
       "1  39  ENCHILADAS NORTE√ëA(DESAYUNOS GAHORY)   \n",
       "2  40    ENCHILADAS SUIZO(DESAYUNOS GAHORY)   \n",
       "3  41  ENCHILADAS DELICIA(DESAYUNOS GAHORY)   \n",
       "4  42    ENCHILADAS PAISA(DESAYUNOS GAHORY)   \n",
       "\n",
       "                                       description  price  \\\n",
       "0                   CAMPIRANO:VERDES:POLLO / HUEVO   70.0   \n",
       "1                ROJAS C/PECHUGA ASADA ENCEBOLLADA   85.0   \n",
       "2  EN SALSA CREMOSITA GRATINADAS EN QUESO MANCHEGO   95.0   \n",
       "3                                      DIVORCIADAS   85.0   \n",
       "4                    ENCHILADAS EN SALSA DE FRIJOL   85.0   \n",
       "\n",
       "                                              image1  \\\n",
       "0  https://firebasestorage.googleapis.com/v0/b/te...   \n",
       "1  https://firebasestorage.googleapis.com/v0/b/te...   \n",
       "2  https://firebasestorage.googleapis.com/v0/b/te...   \n",
       "3  https://firebasestorage.googleapis.com/v0/b/te...   \n",
       "4  https://firebasestorage.googleapis.com/v0/b/te...   \n",
       "\n",
       "                                              image2  \\\n",
       "0  https://firebasestorage.googleapis.com/v0/b/te...   \n",
       "1  https://firebasestorage.googleapis.com/v0/b/te...   \n",
       "2  https://firebasestorage.googleapis.com/v0/b/te...   \n",
       "3  https://firebasestorage.googleapis.com/v0/b/te...   \n",
       "4  https://firebasestorage.googleapis.com/v0/b/te...   \n",
       "\n",
       "                                              image3  id_category  \n",
       "0  https://firebasestorage.googleapis.com/v0/b/te...           34  \n",
       "1  https://firebasestorage.googleapis.com/v0/b/te...           34  \n",
       "2  https://firebasestorage.googleapis.com/v0/b/te...           34  \n",
       "3  https://firebasestorage.googleapis.com/v0/b/te...           34  \n",
       "4  https://firebasestorage.googleapis.com/v0/b/te...           34  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productos = pd.read_sql(\"\"\"\n",
    "SELECT\n",
    "  id,\n",
    "  name,\n",
    "  description,\n",
    "  price,\n",
    "  image1,\n",
    "  image2,\n",
    "  image3,\n",
    "  id_category\n",
    "FROM products\n",
    "\"\"\", engine)\n",
    "\n",
    "productos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed973a",
   "metadata": {},
   "source": [
    "##### La parte de desnormalizar (preparado el JSON para el RAG): \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "330c4e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Prepara el JSON base desde SQL\n",
    "# ============================================\n",
    "\n",
    "docs = []\n",
    "\n",
    "def clean_time(t):\n",
    "    if pd.isna(t):\n",
    "        return None\n",
    "\n",
    "    if isinstance(t, pd.Timedelta):\n",
    "        total_seconds = int(t.total_seconds())\n",
    "        hours = total_seconds // 3600\n",
    "        minutes = (total_seconds % 3600) // 60\n",
    "        return f\"{hours:02d}:{minutes:02d}\"\n",
    "\n",
    "    if isinstance(t, str):\n",
    "        return t[:5]\n",
    "\n",
    "    if hasattr(t, \"strftime\"):\n",
    "        return t.strftime(\"%H:%M\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def clean_text(t):\n",
    "    if pd.isna(t) or t is None or str(t).strip() == \"\":\n",
    "        return None\n",
    "    return str(t).strip()\n",
    "\n",
    "\n",
    "for _, n in negocios.iterrows():\n",
    "    prods = productos[productos.id_category == n.id]\n",
    "\n",
    "    descripcion_corta = clean_text(n.description)\n",
    "    descripcion_detallada = clean_text(n.descripcion_detallada)\n",
    "\n",
    "    # Fallback inteligente para descripci√≥n\n",
    "    if not descripcion_detallada and descripcion_corta:\n",
    "        descripcion_detallada = f\"Negocio de comida que ofrece {descripcion_corta.lower()}.\"\n",
    "\n",
    "    nombre = clean_text(n[\"name\"])\n",
    "\n",
    "\n",
    "\n",
    "    docs.append({\n",
    "        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        # IDENTIDAD\n",
    "        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        \"document_id\": f\"negocio_{n.id}\",\n",
    "        \"tipo\": \"negocio\",\n",
    "        \"nombre\": nombre,\n",
    "\n",
    "        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        # DESCRIPCIONES\n",
    "        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        \"descripcion_corta\": descripcion_corta,\n",
    "        \"descripcion_detallada\": descripcion_detallada,\n",
    "\n",
    "        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        # UBICACI√ìN\n",
    "        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        \"direccion\": clean_text(n.direccion),\n",
    "\n",
    "        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        # HORARIOS\n",
    "        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        \"horarios\": {\n",
    "            \"dias\": clean_text(n.diasOperacion),\n",
    "            \"apertura\": clean_time(n.horario_apertura),\n",
    "            \"cierre\": clean_time(n.horario_cierre)\n",
    "        },\n",
    "\n",
    "        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        # PRODUCTOS\n",
    "        # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "        \"productos\": (\n",
    "            prods[[\"name\", \"description\", \"price\"]]\n",
    "            .rename(columns={\n",
    "                \"name\": \"nombre\",\n",
    "                \"description\": \"descripcion\",\n",
    "                \"price\": \"precio\"\n",
    "            })\n",
    "            .map(clean_text)        # ‚úÖ CORRECTO\n",
    "            .to_dict(\"records\")\n",
    "        )\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d3fd903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset RAG generado\n"
     ]
    }
   ],
   "source": [
    "#PARA EXPORTAR EL JSON, EL PRIMERO,\n",
    "#CON LOS DATOS ORIGINALES\n",
    "import json\n",
    "\n",
    "with open(\"datos.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(docs, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"‚úÖ Dataset RAG generado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e0d729bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ulise\\AppData\\Local\\Temp\\ipykernel_17460\\1714667455.py:476: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"generated_at\": datetime.utcnow().isoformat() + \"Z\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> generado docs_rag.json con 570 docs (negocio + productos).\n",
      "OK -> generado labels_pendientes.json (pendientes globales).\n",
      "OK -> generado label_registry.json (registro persistente).\n"
     ]
    }
   ],
   "source": [
    "###############LEER IMPORTANTE#################\n",
    "# SISTEMA dise√±ado para aprender de forma robusta.\n",
    "\n",
    "# Cada corrida analiza toda la plataforma (cross-negocio)\n",
    "\n",
    "# Guarda todo en labels_pendientes.json con evidencia\n",
    "\n",
    "# Si activas AUTO_PROMOTE_LABEL=True, promueve solo si:\n",
    "\n",
    "# aparece en muchos negocios\n",
    "\n",
    "# tiene muchas menciones\n",
    "\n",
    "# y no es un t√©rmino basura\n",
    "\n",
    "#Todo queda guardado en label_registry.json y se usa en corridas futuras\n",
    "#######################\n",
    "#¬øQUE ES?\n",
    "# ‚úÖ un motor de conocimiento incremental\n",
    "# ‚úÖ con memoria persistente\n",
    "# ‚úÖ con reglas + evidencia\n",
    "# ‚úÖ listo para RAG / embeddings / b√∫squeda sem√°ntica\n",
    "\n",
    "#######################################\n",
    "\n",
    "# El fin de todo este bloque es convertir texto sucio de negocios \n",
    "# y productos en un sistema de clasificaci√≥n que aprende solo, \n",
    "# recuerda lo aprendido y solo evoluciona cuando hay evidencia \n",
    "# real a nivel plataforma.\n",
    "\n",
    "###########################\n",
    "# Es un sistema de clasificaci√≥n sem√°ntica con aprendizaje heur√≠stico global \n",
    "# y gobernanza autom√°tica, usado como preprocesador para RAG\n",
    "###########################\n",
    "# Genera docs_rag.json (negocio + producto) robusto y auto-actualizable:\n",
    "# - Reglas base (LABEL_RULES)\n",
    "# - Conceptos can√≥nicos (CANONICAL_CONCEPTS) -> tags/booleans\n",
    "# - Aprendizaje GLOBAL cross-negocio: descubre nuevos t√©rminos/phrases\n",
    "# - Registro persistente de labels/tags: label_registry.json\n",
    "# - Pendientes con evidencia: labels_pendientes.json\n",
    "#\n",
    "# Ideal para: Qwen3 + embeddings + Chroma/FAISS + n8n\n",
    "\n",
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "INPUT_DATOS = \"datos.json\"\n",
    "OUTPUT_DOCS_RAG = \"docs_rag.json\"\n",
    "\n",
    "REGISTRY_PATH = \"label_registry.json\" \n",
    "#label_registry.json no se recalcula desde cero\n",
    "# Contiene:\n",
    "# -labels_oficiales: etiquetas confiables para UI, filtros, dashboards\n",
    "# -auto_promoted: historial de etiquetas que el sistema promovi√≥ solo\n",
    "# Sin esto, cada corrida ser√≠a ‚Äúamnesia total‚Äù.\n",
    "# Con esto, el sistema madura con el tiempo.\n",
    "\n",
    "\n",
    "PENDING_PATH = \"labels_pendientes.json\"\n",
    "# Sirve para:\n",
    "# -auditar\n",
    "# -ajustar umbrales\n",
    "# -aprobar manualmente\n",
    "# -entender qu√© est√° aprendiendo el sistema\n",
    "\n",
    "TOP_TAGS_PER_BIZ = 24\n",
    "TOP_CANDIDATES_PER_BIZ = 12\n",
    "\n",
    "MAX_NGRAMS = 2  # 2 = bigramas, 3 = trigramas\n",
    "\n",
    "# Umbrales de ‚Äúaprendizaje global‚Äù\n",
    "# (ajustar seg√∫n tama√±o de la plataforma)\n",
    "MIN_BUSINESSES_FOR_TAG = 2        # para aceptar tags globales\n",
    "MIN_BUSINESSES_FOR_LABEL = 5      # para proponer como label candidata (categor√≠a)\n",
    "AUTO_PROMOTE_LABEL = True         # si True, promueve labels cuando pasa umbral\n",
    "AUTO_PROMOTE_MIN_BUSINESSES = 8   # negocios distintos\n",
    "AUTO_PROMOTE_MIN_TOTAL_MENTIONS = 20  # menciones totales (tokens/ngrams)\n",
    "AUTO_PROMOTE_MIN_LEN = 4          # m√≠nimo largo para auto-promoci√≥n\n",
    "\n",
    "# =========================\n",
    "# Stopwords / ruido\n",
    "# =========================\n",
    "STOPWORDS = {\n",
    "    \"de\",\"la\",\"el\",\"y\",\"o\",\"con\",\"sin\",\"para\",\"por\",\"en\",\"a\",\"al\",\"del\",\"los\",\"las\",\n",
    "    \"un\",\"una\",\"unos\",\"unas\",\"que\",\"se\",\"su\",\"sus\",\"tipo\",\"ofrece\",\"negocio\",\"comida\",\n",
    "    \"incluye\",\"pieza\",\"piezas\",\"orden\",\"ml\",\"lt\",\"l\",\"litro\",\"litros\",\"media\",\"medio\",\n",
    "    \"grande\",\"familiar\",\"especial\",\"clasica\",\"clasico\",\"cl√°sico\",\"clasica\",\"sencilla\",\n",
    "    \"sencillo\",\"combo\",\"paquete\",\"promocion\",\"promoci√≥n\",\"envio\",\"env√≠o\",\"gratis\",\n",
    "    \"desde\",\"hasta\",\"precio\",\"precios\",\"aprox\",\"aproximado\",\"a\",\"elegir\"\n",
    "}\n",
    "\n",
    "GENERIC_MENU_WORDS = {\n",
    "    \"rico\",\"rica\",\"delicioso\",\"deliciosa\",\"sabroso\",\"sabrosa\",\"caliente\",\"crujiente\",\n",
    "    \"suave\",\"casero\",\"casera\",\"artesanal\",\"premium\",\"favorito\",\"favorita\",\n",
    "    \"fresco\",\"fresca\",\"natural\",\"hecho\",\"hecha\",\"especialidad\",\"tradicional\"\n",
    "}\n",
    "\n",
    "UNITS = {\"kg\",\"kilo\",\"kilos\",\"gr\",\"g\",\"ml\",\"lt\",\"l\",\"litro\",\"litros\",\"pz\",\"pza\",\"pzas\",\"pieza\",\"piezas\"}\n",
    "\n",
    "# =========================\n",
    "# Normalizaci√≥n\n",
    "# =========================\n",
    "def normalize(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = text.lower().strip()\n",
    "    text = unicodedata.normalize(\"NFD\", text)\n",
    "    text = \"\".join(ch for ch in text if unicodedata.category(ch) != \"Mn\")\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def tokenize(text: str):\n",
    "    text = normalize(text)\n",
    "    toks = []\n",
    "    for t in text.split():\n",
    "        if not t or t in STOPWORDS:\n",
    "            continue\n",
    "        if len(t) < 3:\n",
    "            continue\n",
    "        if t.isdigit():\n",
    "            continue\n",
    "        if t in UNITS:\n",
    "            continue\n",
    "        if t in GENERIC_MENU_WORDS:\n",
    "            continue\n",
    "        toks.append(t)\n",
    "    return toks\n",
    "\n",
    "def make_ngrams(tokens, n=2):\n",
    "    return [\" \".join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "\n",
    "def is_bad_term(term: str) -> bool:\n",
    "    if not term:\n",
    "        return True\n",
    "    if any(ch.isdigit() for ch in term):\n",
    "        return True\n",
    "    parts = term.split()\n",
    "    if len(parts) == 1:\n",
    "        if len(term) < 3:\n",
    "            return True\n",
    "        if term in STOPWORDS or term in GENERIC_MENU_WORDS or term in UNITS:\n",
    "            return True\n",
    "    # Evita t√©rminos absurdamente gen√©ricos\n",
    "    if term in STOPWORDS or term in GENERIC_MENU_WORDS or term in UNITS:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# =========================\n",
    "# Labels reglas (base)\n",
    "# =========================\n",
    "LABEL_RULES = {\n",
    "    \"tacos\": [\"taco\", \"tacos\", \"taqueria\", \"taquer√≠a\", \"pastor\", \"suadero\", \"bistec\", \"arrachera\", \"longaniza\", \"chistorra\"],\n",
    "    \"pizza\": [\"pizza\", \"pepperoni\", \"hawai\", \"hawaiana\", \"margarita\", \"tokio\", \"suprema\"],\n",
    "    \"hamburguesas\": [\"hamburguesa\", \"burger\", \"hotdog\", \"hot-dog\", \"hot dog\", \"papas\", \"salchipulpos\", \"salchicha\", \"boneless\", \"alitas\"],\n",
    "    \"desayunos\": [\"desayuno\", \"chilaquiles\", \"huevos\", \"hotcakes\", \"omelette\", \"enchiladas\", \"molletes\", \"cafe de olla\", \"tamales\", \"atole\"],\n",
    "    \"cafeteria\": [\"cafe\", \"caf√©\", \"capuchino\", \"latte\", \"moka\", \"frappe\", \"chai\", \"matcha\", \"chocolate caliente\", \"crepa\", \"crepas\"],\n",
    "    \"mariscos\": [\"mariscos\", \"coctel\", \"c√≥ctel\", \"camaron\", \"camar√≥n\", \"mojarra\", \"ceviche\", \"aguachile\"],\n",
    "    \"antojitos\": [\"quesadilla\", \"quesadillas\", \"sopes\", \"sope\", \"gorditas\", \"tlacoyo\", \"tostada\", \"flautas\", \"gringas\", \"huarache\", \"chalupas\"],\n",
    "    \"postres\": [\"pastel\", \"rebanada\", \"galletas\", \"waffles\", \"crepa\", \"nutella\", \"cajeta\", \"bombones\", \"granola\", \"flan\", \"gelatina\", \"churros\", \"helado\"],\n",
    "    \"bebidas\": [\"refresco\", \"coca\", \"cocacola\", \"boing\", \"agua\", \"limonada\", \"jugo\", \"te\", \"t√©\", \"malteada\", \"horchata\", \"jamaica\", \"tamarindo\"],\n",
    "    \"alcohol\": [\"vinateria\", \"vinater√≠a\", \"cerveza\", \"six\", \"laton\", \"lat√≥n\", \"tequila\", \"mezcal\", \"whisky\", \"red label\", \"pulque\", \"michelada\", \"chelada\"],\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Conceptos can√≥nicos (alias -> tag fuerte)\n",
    "# =========================\n",
    "CANONICAL_CONCEPTS = {\n",
    "    \"comida corrida\": [\n",
    "        \"comida corrida\", \"cocina economica\", \"cocina econ√≥mica\",\n",
    "        \"fonda\", \"comedor\", \"menu del dia\", \"men√∫ del d√≠a\",\n",
    "        \"guisados\", \"comida casera\", \"corrida\"\n",
    "    ],\n",
    "    \"tacos de canasta\": [\"tacos de canasta\", \"tacos sudados\", \"tacos al vapor\"],\n",
    "    \"barbacoa\": [\"barbacoa\", \"consome de barbacoa\", \"consom√© de barbacoa\"],\n",
    "    \"birria\": [\"birria\", \"consome\", \"consom√©\"],\n",
    "    \"carnitas\": [\"carnitas\"],\n",
    "    \"cochinita pibil\": [\"cochinita\", \"pibil\", \"cochinita pibil\"],\n",
    "}\n",
    "\n",
    "def apply_canonical_tags(full_text: str):\n",
    "    norm = normalize(full_text)\n",
    "    tags = set()\n",
    "    for canon, variants in CANONICAL_CONCEPTS.items():\n",
    "        for v in variants:\n",
    "            if normalize(v) in norm:\n",
    "                tags.add(canon)\n",
    "                break\n",
    "    return tags\n",
    "\n",
    "# =========================\n",
    "# Construcci√≥n texto\n",
    "# =========================\n",
    "def build_full_text_business(biz: dict) -> str:\n",
    "    nombre = str(biz.get(\"nombre\", \"\") or \"\")\n",
    "    dc = str(biz.get(\"descripcion_corta\", \"\") or \"\")\n",
    "    dd = str(biz.get(\"descripcion_detallada\", \"\") or \"\")\n",
    "    prod_text_parts = []\n",
    "    for p in biz.get(\"productos\", []) or []:\n",
    "        prod_text_parts.append(str((p or {}).get(\"nombre\", \"\") or \"\"))\n",
    "        prod_text_parts.append(str((p or {}).get(\"descripcion\", \"\") or \"\"))\n",
    "    return \" \".join([nombre, dc, dd, \" \".join(prod_text_parts)])\n",
    "\n",
    "def build_full_text_product(biz: dict, p: dict) -> str:\n",
    "    return \" \".join([\n",
    "        str(biz.get(\"nombre\", \"\") or \"\"),\n",
    "        str(biz.get(\"descripcion_corta\", \"\") or \"\"),\n",
    "        str((p or {}).get(\"nombre\", \"\") or \"\"),\n",
    "        str((p or {}).get(\"descripcion\", \"\") or \"\")\n",
    "    ])\n",
    "\n",
    "# =========================\n",
    "# Aprendizaje global (cross-negocio)\n",
    "# =========================\n",
    "\n",
    "def learn_global_terms(data):\n",
    "\n",
    "        #El fin: detectar patrones a nivel plataforma, no casos aislados.\n",
    "        #Aqu√≠ es donde se hace la magia para que se autoalimente de conceptos \n",
    "        #de negocios nuevos.\n",
    "        #¬øQU√â HACE PASO A PASO?\n",
    "                #Aparece ‚Äúramen‚Äù en muchos negocios\n",
    "                # El sistema lo detecta como:\n",
    "\n",
    "                # {\n",
    "                #   \"term\": \"ramen\",\n",
    "                #   \"kind\": \"label\",\n",
    "                #   \"businesses\": 9,\n",
    "                #   \"total_mentions\": 34\n",
    "                # }\n",
    "\n",
    "                # Si cumple:\n",
    "                # -se auto-promueve\n",
    "                # -se guarda en label_registry.json\n",
    "                # Resultado:\n",
    "                # -Sin escribir reglas\n",
    "                # -Sin entrenar modelo\n",
    "                # -Sin tocar c√≥digo\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Retorna:\n",
    "    - term_counts: conteo total (tokens y ngrams)\n",
    "    - term_businesses: set de negocios donde aparece cada t√©rmino\n",
    "    - examples: ejemplos (nombre de negocio)\n",
    "    \"\"\"\n",
    "    term_counts = Counter()\n",
    "    term_businesses = defaultdict(set)\n",
    "    examples = defaultdict(list)\n",
    "\n",
    "    for biz in data:\n",
    "        negocio_id = biz.get(\"document_id\") or \"\"\n",
    "        full = build_full_text_business(biz)\n",
    "        toks = tokenize(full)\n",
    "\n",
    "        # tokens\n",
    "        uniq_tokens = set(toks)\n",
    "        for t in uniq_tokens:\n",
    "            if is_bad_term(t):\n",
    "                continue\n",
    "            term_businesses[t].add(negocio_id)\n",
    "\n",
    "        term_counts.update([t for t in toks if not is_bad_term(t)])\n",
    "\n",
    "        # ngrams\n",
    "        if MAX_NGRAMS >= 2:\n",
    "            bgs = make_ngrams(toks, 2)\n",
    "            term_counts.update([bg for bg in bgs if not is_bad_term(bg)])\n",
    "            for bg in set(bgs):\n",
    "                if not is_bad_term(bg):\n",
    "                    term_businesses[bg].add(negocio_id)\n",
    "\n",
    "        if MAX_NGRAMS >= 3:\n",
    "            tgs = make_ngrams(toks, 3)\n",
    "            term_counts.update([tg for tg in tgs if not is_bad_term(tg)])\n",
    "            for tg in set(tgs):\n",
    "                if not is_bad_term(tg):\n",
    "                    term_businesses[tg].add(negocio_id)\n",
    "\n",
    "        # ejemplos\n",
    "        biz_name = normalize(biz.get(\"nombre\",\"\") or \"\")\n",
    "        for t in list(uniq_tokens)[:20]:\n",
    "            if len(examples[t]) < 3:\n",
    "                examples[t].append(biz_name)\n",
    "\n",
    "    return term_counts, term_businesses, examples\n",
    "\n",
    "# =========================\n",
    "# Registro persistente (labels oficiales y promociones)\n",
    "# =========================\n",
    "def load_registry():\n",
    "    if not Path(REGISTRY_PATH).exists():\n",
    "        return {\n",
    "            \"created_at\": datetime.utcnow().isoformat() + \"Z\",\n",
    "            \"labels_oficiales\": sorted(list(LABEL_RULES.keys())),\n",
    "            \"auto_promoted\": [],\n",
    "            \"notes\": \"labels_oficiales se usa para filtros y UI; LABEL_RULES sigue siendo tu clasificador por keywords.\",\n",
    "        }\n",
    "\n",
    "\n",
    "    return json.loads(Path(REGISTRY_PATH).read_text(encoding=\"utf-8\"))\n",
    "\n",
    "def save_registry(registry):\n",
    "    Path(REGISTRY_PATH).write_text(json.dumps(registry, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# =========================\n",
    "# Extracci√≥n local (por negocio) con apoyo global\n",
    "# =========================\n",
    "def extract_tags_local(full_text: str):\n",
    "    toks = tokenize(full_text)\n",
    "    cnt = Counter(toks)\n",
    "\n",
    "    if MAX_NGRAMS >= 2:\n",
    "        cnt.update(make_ngrams(toks, 2))\n",
    "    if MAX_NGRAMS >= 3:\n",
    "        cnt.update(make_ngrams(toks, 3))\n",
    "\n",
    "    # ordenado por frecuencia local\n",
    "    items = [(w,c) for w,c in cnt.items() if not is_bad_term(w)]\n",
    "    items.sort(key=lambda x: (-x[1], x[0]))\n",
    "    return [w for w,_ in items[:TOP_TAGS_PER_BIZ]]\n",
    "\n",
    "def extract_candidates_from_global(term_counts, term_businesses, registry):\n",
    "    \"\"\"\n",
    "    Produce candidatas \"de plataforma\" (robustas), no solo del negocio.\n",
    "    \"\"\"\n",
    "    pending = []\n",
    "\n",
    "    labels_oficiales = set([normalize(x) for x in registry.get(\"labels_oficiales\", [])])\n",
    "    base_labels = set([normalize(x) for x in LABEL_RULES.keys()])\n",
    "\n",
    "    for term, total_count in term_counts.items():\n",
    "        if is_bad_term(term):\n",
    "            continue\n",
    "\n",
    "        biz_count = len(term_businesses.get(term, set()))\n",
    "        if biz_count < MIN_BUSINESSES_FOR_TAG:\n",
    "            continue\n",
    "\n",
    "        # Decide si es candidata a label (categor√≠a) por evidencia fuerte\n",
    "        is_label_candidate = biz_count >= MIN_BUSINESSES_FOR_LABEL\n",
    "\n",
    "        # Evita promover cosas que ya son label base/oficial\n",
    "        term_norm = normalize(term)\n",
    "        already_label = (term_norm in labels_oficiales) or (term_norm in base_labels)\n",
    "\n",
    "        pending.append({\n",
    "            \"term\": term,\n",
    "            \"term_norm\": term_norm,\n",
    "            \"total_mentions\": int(total_count),\n",
    "            \"businesses\": int(biz_count),\n",
    "            \"kind\": \"label\" if (is_label_candidate and not already_label) else \"tag\",\n",
    "            \"already_label\": bool(already_label),\n",
    "        })\n",
    "\n",
    "    pending.sort(key=lambda x: (-x[\"businesses\"], -x[\"total_mentions\"], x[\"term_norm\"]))\n",
    "    return pending\n",
    "\n",
    "def maybe_auto_promote(pending, registry):\n",
    "    if not AUTO_PROMOTE_LABEL:\n",
    "        return registry\n",
    "\n",
    "    labels_oficiales = set([normalize(x) for x in registry.get(\"labels_oficiales\", [])])\n",
    "\n",
    "    for item in pending:\n",
    "        if item[\"kind\"] != \"label\":\n",
    "            continue\n",
    "        if item[\"already_label\"]:\n",
    "            continue\n",
    "        if item[\"businesses\"] < AUTO_PROMOTE_MIN_BUSINESSES:\n",
    "            continue\n",
    "        if item[\"total_mentions\"] < AUTO_PROMOTE_MIN_TOTAL_MENTIONS:\n",
    "            continue\n",
    "        if len(item[\"term_norm\"]) < AUTO_PROMOTE_MIN_LEN:\n",
    "            continue\n",
    "\n",
    "        # Promueve como label oficial (para UI/filtros)\n",
    "        if item[\"term_norm\"] not in labels_oficiales:\n",
    "            registry.setdefault(\"labels_oficiales\", []).append(item[\"term_norm\"])\n",
    "            registry.setdefault(\"auto_promoted\", []).append({\n",
    "                \"label\": item[\"term_norm\"],\n",
    "                \"businesses\": item[\"businesses\"],\n",
    "                \"total_mentions\": item[\"total_mentions\"],\n",
    "                \"promoted_at\": datetime.utcnow().isoformat() + \"Z\"\n",
    "            })\n",
    "            labels_oficiales.add(item[\"term_norm\"])\n",
    "\n",
    "    registry[\"labels_oficiales\"] = sorted(list(set(registry[\"labels_oficiales\"])))\n",
    "    return registry\n",
    "\n",
    "                    #El fin de labels_oficiales es separar la clasificaci√≥n \n",
    "                    #estable de descubrimiento experimental:\n",
    "                        # üîπ Qu√© hace exactamente:\n",
    "                        #     -Las LABEL_RULES = reglas duras (tacos, pizza, etc.)\n",
    "                        #     -labels_oficiales = nuevo vocabulario confiable\n",
    "                        #     Ej: sushi, ramen, poke, vegan\n",
    "\n",
    "                        #    Una vez que algo entra aqu√≠:\n",
    "                        #     -ya se usa en clasificaci√≥n\n",
    "                        #     -ya se usa en metadata\n",
    "                        #     -ya se usa en b√∫squeda / filtros / RAG\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Clasificaci√≥n por reglas + tags/can√≥nicos + labels oficiales\n",
    "# =========================\n",
    "def generate_labels_tags_for_business(biz: dict, registry):\n",
    "    full_text = build_full_text_business(biz)\n",
    "    norm_full = normalize(full_text)\n",
    "\n",
    "    labels = set()\n",
    "    # 1) labels por reglas base\n",
    "    for label, kws in LABEL_RULES.items():\n",
    "        for kw in kws:\n",
    "            if normalize(kw) in norm_full:\n",
    "                labels.add(label)\n",
    "                break\n",
    "\n",
    "    # 2) tags (can√≥nicos + locales)\n",
    "    tags = set()\n",
    "    tags |= apply_canonical_tags(full_text)\n",
    "    tags |= set(extract_tags_local(full_text))\n",
    "\n",
    "    # 3) ‚Äúlabels_oficiales‚Äù detectados por presencia textual (suave)\n",
    "    #    (Sirve para cuando auto-promueves algo como \"sushi\", \"ramen\", etc.)\n",
    "    for lbl in registry.get(\"labels_oficiales\", []):\n",
    "        if not lbl:\n",
    "            continue\n",
    "        if normalize(lbl) in norm_full:\n",
    "            labels.add(normalize(lbl))\n",
    "\n",
    "    # boost de comida corrida\n",
    "    if \"comida corrida\" in tags:\n",
    "        labels.add(\"comida_casera\")\n",
    "\n",
    "    return sorted(labels), sorted(tags)\n",
    "\n",
    "def join_str(values):\n",
    "    if not values:\n",
    "        return \"\"\n",
    "    return \"|\".join([normalize(str(v)) for v in values])\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "def main():\n",
    "    data = json.loads(Path(INPUT_DATOS).read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    # 1) Aprendizaje global (cross-negocio)\n",
    "    term_counts, term_businesses, examples = learn_global_terms(data)\n",
    "\n",
    "    # 2) Registro persistente\n",
    "    registry = load_registry()\n",
    "\n",
    "    # 3) Pendientes globales y auto-promoci√≥n (opcional)\n",
    "    pending = extract_candidates_from_global(term_counts, term_businesses, registry)\n",
    "    registry = maybe_auto_promote(pending, registry)\n",
    "    save_registry(registry)\n",
    "\n",
    "    # 4) Guardar pendientes con ejemplos\n",
    "    # a√±ade ejemplos (m√°ximo 3)\n",
    "    for it in pending[:500]:\n",
    "        ex = examples.get(it[\"term\"], [])[:3]\n",
    "        it[\"examples_businesses\"] = ex\n",
    "\n",
    "    Path(PENDING_PATH).write_text(\n",
    "        json.dumps({\n",
    "            \"generated_at\": datetime.utcnow().isoformat() + \"Z\",\n",
    "            \"min_businesses_for_tag\": MIN_BUSINESSES_FOR_TAG,\n",
    "            \"min_businesses_for_label\": MIN_BUSINESSES_FOR_LABEL,\n",
    "            \"auto_promote_label\": AUTO_PROMOTE_LABEL,\n",
    "            \"pending\": pending[:500],\n",
    "        }, ensure_ascii=False, indent=2),\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    # 5) Generaci√≥n docs negocio + producto\n",
    "    docs = []\n",
    "\n",
    "    for biz in data:\n",
    "        negocio_id = biz.get(\"document_id\")\n",
    "        if not negocio_id:\n",
    "            continue\n",
    "\n",
    "        labels, tags = generate_labels_tags_for_business(biz, registry)\n",
    "\n",
    "        is_comida_corrida = (\"comida corrida\" in tags)\n",
    "        is_tacos = (\"tacos\" in labels)\n",
    "        is_pizza = (\"pizza\" in labels)\n",
    "        is_hamburguesas = (\"hamburguesas\" in labels)\n",
    "\n",
    "        # ========= Doc NEGOCIO =========\n",
    "        business_text = build_full_text_business(biz)\n",
    "        text_negocio = \"\\n\".join([\n",
    "            \"tipo_doc: negocio\",\n",
    "            f\"negocio_id: {negocio_id}\",\n",
    "            f\"nombre: {biz.get('nombre','')}\",\n",
    "            f\"descripcion: {biz.get('descripcion_corta','')} {biz.get('descripcion_detallada','')}\",\n",
    "            f\"direccion: {biz.get('direccion','')}\",\n",
    "            f\"horarios: {(biz.get('horarios') or {}).get('dias','')} {(biz.get('horarios') or {}).get('apertura','')} {(biz.get('horarios') or {}).get('cierre','')}\",\n",
    "            f\"labels: {', '.join(labels) if labels else 'ninguno'}\",\n",
    "            f\"tags: {', '.join(tags) if tags else 'ninguno'}\",\n",
    "            f\"productos: {normalize(business_text)}\"\n",
    "        ])\n",
    "\n",
    "        docs.append({\n",
    "            \"id\": f\"{negocio_id}\",\n",
    "            \"text\": text_negocio,\n",
    "            \"metadata\": {\n",
    "                \"tipo_doc\": \"negocio\",\n",
    "                \"negocio_id\": negocio_id,\n",
    "                \"nombre\": biz.get(\"nombre\"),\n",
    "                \"direccion\": biz.get(\"direccion\"),\n",
    "                \"dias\": (biz.get(\"horarios\") or {}).get(\"dias\"),\n",
    "                \"apertura\": (biz.get(\"horarios\") or {}).get(\"apertura\"),\n",
    "                \"cierre\": (biz.get(\"horarios\") or {}).get(\"cierre\"),\n",
    "\n",
    "                \"labels\": labels,\n",
    "                \"tags\": tags,\n",
    "\n",
    "                \"labels_str\": join_str(labels),\n",
    "                \"tags_str\": join_str(tags),\n",
    "\n",
    "                \"is_comida_corrida\": bool(is_comida_corrida),\n",
    "                \"is_tacos\": bool(is_tacos),\n",
    "                \"is_pizza\": bool(is_pizza),\n",
    "                \"is_hamburguesas\": bool(is_hamburguesas),\n",
    "\n",
    "                # info para debug/observabilidad\n",
    "                \"labels_oficiales_count\": len(registry.get(\"labels_oficiales\", [])),\n",
    "            }\n",
    "        })\n",
    "\n",
    "        # ========= Docs PRODUCTO =========\n",
    "        for idx, p in enumerate(biz.get(\"productos\", []) or []):\n",
    "            prod_name = (p or {}).get(\"nombre\")\n",
    "            prod_desc = (p or {}).get(\"descripcion\")\n",
    "            prod_price = (p or {}).get(\"precio\")\n",
    "            if not (prod_name or prod_desc):\n",
    "                continue\n",
    "\n",
    "            product_id = f\"{negocio_id}::producto_{idx+1}\"\n",
    "            product_text_raw = build_full_text_product(biz, p)\n",
    "\n",
    "            text_producto = \"\\n\".join([\n",
    "                \"tipo_doc: producto\",\n",
    "                f\"negocio_id: {negocio_id}\",\n",
    "                f\"nombre_negocio: {biz.get('nombre','')}\",\n",
    "                f\"producto_id: {product_id}\",\n",
    "                f\"producto: {prod_name or ''}\",\n",
    "                f\"descripcion_producto: {prod_desc or ''}\",\n",
    "                f\"precio: {prod_price or ''}\",\n",
    "                f\"labels: {', '.join(labels) if labels else 'ninguno'}\",\n",
    "                f\"tags: {', '.join(tags) if tags else 'ninguno'}\",\n",
    "                f\"texto: {normalize(product_text_raw)}\"\n",
    "            ])\n",
    "\n",
    "            docs.append({\n",
    "                \"id\": product_id,\n",
    "                \"text\": text_producto,\n",
    "                \"metadata\": {\n",
    "                    \"tipo_doc\": \"producto\",\n",
    "                    \"negocio_id\": negocio_id,\n",
    "                    \"nombre_negocio\": biz.get(\"nombre\"),\n",
    "                    \"producto_id\": product_id,\n",
    "                    \"producto_nombre\": prod_name,\n",
    "                    \"producto_precio\": prod_price,\n",
    "\n",
    "                    \"labels\": labels,\n",
    "                    \"tags\": tags,\n",
    "\n",
    "                    \"labels_str\": join_str(labels),\n",
    "                    \"tags_str\": join_str(tags),\n",
    "\n",
    "                    \"is_comida_corrida\": bool(is_comida_corrida),\n",
    "                    \"is_tacos\": bool(is_tacos),\n",
    "                    \"is_pizza\": bool(is_pizza),\n",
    "                    \"is_hamburguesas\": bool(is_hamburguesas),\n",
    "                }\n",
    "            })\n",
    "\n",
    "    Path(OUTPUT_DOCS_RAG).write_text(\n",
    "        json.dumps(docs, ensure_ascii=False, indent=2),\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    print(f\"OK -> generado {OUTPUT_DOCS_RAG} con {len(docs)} docs (negocio + productos).\")\n",
    "    print(f\"OK -> generado {PENDING_PATH} (pendientes globales).\")\n",
    "    print(f\"OK -> generado {REGISTRY_PATH} (registro persistente).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b41325c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede4ea25",
   "metadata": {},
   "source": [
    "##### Texto listo para embeddings (Convierte cada negocio en un texto listo para embeddings.) Es aprendizaje automatico de docs_rag.json, en pocas palabras es ML\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
